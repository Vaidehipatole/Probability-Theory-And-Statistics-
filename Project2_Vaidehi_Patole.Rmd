<CENTER>
<FONT SIZE=4, COLOR="#8272E9">
<B>Vaidehi Patole</b>
<BR>
<BR><B>Probability Theory and Introductory to Statistics</B> <BR>
<B>M1 Project Report</B><BR>
<BR>
<B>ALY6010 - 70487 </B>
<BR>
<B>Northeastern University</B>
<BR>
<B>Dr. Dee Chiluiza, PhD</B>
<BR>
`r format(Sys.time(), "%d %B, %Y")`
</CENTER></FONT></B>
<P>
<FONT SIZE=4, COLOR="#8272E9"><B>INTRODUCTION</B></FONT>
<P>
<b><br> Salary surveys their uses and Importance</b><br>

Employees are the most valuable asset that any company can have. Fair compensation is critical when it comes to giving employees a positive experience, reducing attrition, and attracting top talent to the firm.

A compensation survey is one technique that your firm may use to ensure that you are paying your employees a fair wage and benefits package. A compensation survey is beneficial to your company for a variety of reasons.
1)	Ensure that employers are aware of salary trends
2)	Ensure that companies hire and retain the best staff.
3)	Establish a culture of consistency and openness.

<b><br>Confidence Interval</b><br>

Instead of a single estimate, a confidence interval (CI) in statistics is a range of plausible values for an unknown parameter (for example, a population mean). There is a level of confidence connected with the interval. The most common confidence level is 95 percent, however other values, such as 90 percent or 99 percent, are occasionally employed. The confidence level is the long-term frequency of confidence intervals containing the true value of an unknown population parameter. In other words, 95 percent of confidence intervals computed at the 95 percent confidence level, as well as other confidence levels, contain the parameter. The target confidence level, sample size, and the width of the CI are all factors that influence its width

<b><br>Pratical Application of confidence interval</b><br>

<b><br>Biology</b><br>
In biology, confidence intervals are frequently used to estimate the mean height, weight, width, diameter, and other characteristics of various plant and animal species.
A biologist, for example, would be interested in determining the average weight of a certain frog species in Australia. Because weighing thousands of individual frogs would take too long, the scientist may instead gather a simple random sample of 50 frogs and calculate the mean and standard deviation of the frogs in the sample.

<b><br> Advertising</b><br>
Marketing departments frequently utilize confidence intervals to see if a new advertising technique, method, tactic, or other strategy generates significantly more income.
For example, during one quarter, a grocery retailer's marketing team might execute two distinct advertising campaigns at 20 different locations, measuring the average sales generated by each campaign at each store at the conclusion of the quarter.
They might then calculate a confidence interval for the difference between mean sales using the sample mean and sample standard deviation of sales from each campaign. This will inform the marketing team whether there is a significant difference in sales as a result of the rebranding.


<b><br>Manufacturing</b><br>
Engineers at manufacturing plants frequently utilize confidence intervals to see if a new process, methodology, approach, or other factor has a significant impact on the number of defective items produced.

For instance, an engineer might assume that a new procedure will reduce the existing 50 defective widgets generated every day. To test this, he might install the new method and keep track of how many defective items are created each day at the plant for a month.


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



```{r include=FALSE}
library(readxl)
M2Data <- read_excel("DataSets/M2Data.xlsx",
                     sheet = "salary_survey",col_types = c("numeric",
                                                           "numeric","numeric","numeric",
                                                           "numeric","numeric","numeric",
                                                           "numeric","numeric","numeric",
                                                           "numeric","numeric","numeric",
                                                           "numeric","numeric","numeric",
                                                           "numeric","numeric","numeric",
                                                           "numeric"))
M2Data

```

```{r}


Salary_Survey_vec <-data.frame(newcol = c(t(M2Data[1:20])), stringsAsFactors=FALSE)


```

```{r}
#Calculating Confidence Interval as A Whole 
Salary_S_df = as.data.frame(M2Data)
sum_all_stores = sum(Salary_S_df,na.rm = TRUE)
n = as.numeric(sum(!is.na(Salary_S_df) == TRUE)) 
sum_all_stores = sum(Salary_S_df,na.rm = TRUE)
Mean_All_Stores = sum_all_stores/n


```

```{r}


Standard_Deviation_all_Stores = sd(na.omit(M2Data$newcol))
All_Store_df = data.frame()



```

<b><br> Task 1] Confidence interval of 95%,97% and 99% </b><br>

```{r}
#Confidence Intreval 95%
Z_For_95 = qnorm((1+0.95)/2)
E_For_95 = Z_For_95*(Standard_Deviation_all_Stores/sqrt(n))
CLup = Mean_All_Stores + E_For_95
CLlow = Mean_All_Stores - E_For_95
intercepts_95= data.frame("95%",round(CLlow,3),round(Mean_All_Stores,3),round(CLup,3),round(E_For_95,3),round(E_For_95,3)*2)
colnames(intercepts_95) <- c("percentage", "CLLOW", "MEAN", "CLUP", "MOE" , "CLWIDTH")

```

```{r}
#Confidence Interval 97%
Z_For_97 = qnorm((1+0.97)/2)
E_For_97 = Z_For_97*(Standard_Deviation_all_Stores/sqrt(n))
CLup = Mean_All_Stores + E_For_97
CLlow = Mean_All_Stores - E_For_97
intercepts_97= data.frame("97%",round(CLlow,3),round(Mean_All_Stores,3),round(CLup,3),round(E_For_97,3),round(E_For_97,3)*2)
colnames(intercepts_97) <- c("percentage", "CLLOW", "MEAN", "CLUP", "MOE" , "CLWIDTH")
```

```{r}
#Confidence Interval 99%
Z_For_99 = qnorm((1+0.99)/2)
E_For_99 = Z_For_99*(Standard_Deviation_all_Stores/sqrt(n))
CLup = Mean_All_Stores + E_For_99
CLlow = Mean_All_Stores - E_For_99
intercepts_99= data.frame("99%",round(CLlow,3),round(Mean_All_Stores,3),round(CLup,3),round(E_For_99,3),round(E_For_99,3)*2)
colnames(intercepts_99) <- c("percentage", "CLLOW", "MEAN", "CLUP", "MOE" , "CLWIDTH")

```

```{r}
All_Store_df = rbind(All_Store_df,intercepts_95)
All_Store_df = rbind(All_Store_df,intercepts_97)
All_Store_df = rbind(All_Store_df,intercepts_99)
All_Store_df = rbind(All_Store_df,intercepts_95)
All_Store_df = rbind(All_Store_df,intercepts_97)
All_Store_df = rbind(All_Store_df,intercepts_99)
Final_Table_2 = (All_Store_df)

```
<b><br> Observation 1 </b><br>
 
1.As the confidence level rises, the width of the interval widens.

2.As the confidence interval widens, the margin of error widens as well.

3.As the level climbed, the lower limit of the confidence interval grew, while the upper limit grew.

4.The sample's mean value is 12.216.



<b><br> Task 2 ]Confidence Interval of stores </b><br>
```{r}

# Confidence interval Per store

store_mean = c(t(sapply(Salary_S_df, function(x) mean(x, na.rm = TRUE))))
store_sd = c(t(sapply(Salary_S_df, function(x) sd(x, na.rm = TRUE))))
a <- data.frame(store_mean = store_mean, store_sd = store_sd, row.names = names(M2Data))
aver_mean_All_stores = sum(a$store_mean)/20
aver_sd_all_stores = sum(a$store_sd)/20
per_store_df = data.frame()

```

```{r}
#Confidence Intreval 95%
Tc_for_95 = qt((1+0.95)/2,20-1)
Moe_95 = Tc_for_95*(aver_sd_all_stores/sqrt(20))
clUp_per_95 = aver_mean_All_stores + Moe_95
clLow_95 = aver_mean_All_stores - Moe_95
ClWidth_per_95 = Moe_95*2  
intercepts_per_95= data.frame("95%",round(clLow_95,3),round(aver_mean_All_stores,3),round(clUp_per_95,3),round(Moe_95,3),round(ClWidth_per_95,3))
colnames(intercepts_per_95) <- c("percentage", "CLLOW", "MEAN", "CLUP", "MOE" , "CLWIDTH")


```

```{r}
#Confidence Intreval 97%
Tc_for_97 = qt((1+0.97)/2,20-1)
Moe_97 = Tc_for_95*(aver_sd_all_stores/sqrt(20))
clUp_per_97 = aver_mean_All_stores + Moe_97
clLow_97 = aver_mean_All_stores - Moe_97
ClWidth_per_97 = Moe_97*2  
intercepts_per_97= data.frame("97%",round(clLow_97,3),round(aver_mean_All_stores,3),round(clUp_per_97,3),round(Moe_97,3),round(ClWidth_per_97,3))
colnames(intercepts_per_97) <- c("percentage", "CLLOW", "MEAN", "CLUP", "MOE" , "CLWIDTH")




```

```{r}
#Confidence Intreval 99%
Tc_for_99 = qt((1+0.99)/2,20-1)
Moe_99 = Tc_for_99*(aver_sd_all_stores/sqrt(20))
clUp_per_99 = aver_mean_All_stores + Moe_99
clLow_99 = aver_mean_All_stores - Moe_99
ClWidth_per_99 = Moe_99*2     
intercepts_per_99= data.frame("99%",round(clLow_99,3),round(aver_mean_All_stores,3),round(clUp_per_99,3),round(Moe_99,3),round(ClWidth_per_99,3))
colnames(intercepts_per_99) <- c("percentage", "CLLOW", "MEAN", "CLUP", "MOE" , "CLWIDTH")


```


```{r}
per_store_df = rbind(per_store_df,intercepts_per_95)
per_store_df = rbind(per_store_df,intercepts_per_97)
per_store_df = rbind(per_store_df,intercepts_per_99)
Final_Table_1 = (per_store_df)
```
![](D:\Users\Admin\Desktop\\Per store.PNG)

<b><br> Observation 2 </b><br>

1.When compared to the mean value of hourly pay for all stores combined, the average mean per store is higher.
2.When the average mean and standard deviation were determined per store rather than the entire dataset as a whole, the margin of error expanded considerably.
3.The sample's average value is 12.3.



<b><br> Task 3] Boxplot </b><br>
```{r}
stats1 = round(boxplot.stats(Salary_S_df$`Store 1`)$stats,1) 
stats2 = round(boxplot.stats(Salary_S_df$`Store 2`)$stats,1) 
stats3 = round(boxplot.stats(Salary_S_df$`Store 3`)$stats,1) 
stats4 = round(boxplot.stats(Salary_S_df$`Store 4`)$stats,1) 
stats5 = round(boxplot.stats(Salary_S_df$`Store 5`)$stats,1)
stats6 = round(boxplot.stats(Salary_S_df$`Store 6`)$stats,1) 
stats7 = round(boxplot.stats(Salary_S_df$`Store 7`)$stats,1)
stats8 = round(boxplot.stats(Salary_S_df$`Store 8`)$stats,1)
stats9 = round(boxplot.stats(Salary_S_df$`Store 9`)$stats,1)
stats10 = round(boxplot.stats(Salary_S_df$`Store 10`)$stats,1) 
stats11 = round(boxplot.stats(Salary_S_df$`Store 11`)$stats,1)
stats12 = round(boxplot.stats(Salary_S_df$`Store 12`)$stats,1)
stats13 = round(boxplot.stats(Salary_S_df$`Store 13`)$stats,1)
stats14 = round(boxplot.stats(Salary_S_df$`Store 14`)$stats,1)
stats15 = round(boxplot.stats(Salary_S_df$`Store 15`)$stats,1)
stats16 = round(boxplot.stats(Salary_S_df$`Store 16`)$stats,1)
stats17 = round(boxplot.stats(Salary_S_df$`Store 17`)$stats,1)
stats18 = round(boxplot.stats(Salary_S_df$`Store 18`)$stats,1)
stats19 = round(boxplot.stats(Salary_S_df$`Store 19`)$stats,1)
stats20 = round(boxplot.stats(Salary_S_df$`Store 20`)$stats,1)

k = as.data.frame(sapply(Salary_S_df, boxplot.stats)[1,])

Labels_box = rbind(stats1,stats2,stats3,stats4,stats5,stats6,stats7,stats8,stats9,stats10,stats11,stats12,stats13,stats14,
                   stats15,stats16,stats17,stats18,stats19,stats20)
boxplot(M2Data , las = 3 , main = "Income Per Store", ylim = c(7,18))
points(M2Data, pch = 20 , col = "blue")
       

```
<b><br> Observation 3 </b><br>

1.Nearly half of the stores in the dataset have mean wages that are higher than median wages, indicating that they are positively skewed.
2.Compared to other retailers, Store 19 pays the highest median wage of 14.8 per hour to clerks.
3.The lowest hourly wage for clerks is offered by Store 1.
4.Store 20 pays hourly compensation to all employees in a very identical pricing range.


<b><br> Difference between T and Z confidence Interval </b><br>
When the sample size is big, such as when n>30, the Z- test is used, and when the sample size is less than 30 the T- test is used.
In the Z-test, the standard deviation and variance of the population are known, whereas in the T-Test, the variance and standard deviation are unknown.
![](D:\Users\Admin\Desktop\\Z distribution.PNG)

```{r}
PetSS = read_excel("DataSets/M2data.xlsx",sheet = "pets",col_names = FALSE)


```


```{r}
Pet_No = sum(sapply(PetSS, function(x) ifelse(x=="No",TRUE,FALSE)))
len = length(sapply(PetSS, function(x) ifelse(x=="Yes",TRUE,FALSE)))
Pet_Yes = sum(sapply(PetSS, function(x) ifelse(x=="Yes",TRUE,FALSE)))

```

```{r}
P_Yes = Pet_Yes/len
P_No = Pet_No/len
Final_df = data.frame()
Z_90 = qnorm((1+0.90)/2)
E_90 = Z_90*sqrt((P_Yes*P_No)/len)
CIUP_90 = P_Yes + E_90
CILOW_90 = P_Yes - E_90
CIMID_90 = E_90
CIWidth_90 = 2*E_90
intercepts_90 = data.frame("90%",round(CIUP_90,3),round(CILOW_90,3),round(CIWidth_90,3),round(E_90,3))
colnames(intercepts_90) <- c("percentage", "CLUPPER", "CILOWER", "CIWIDTH" , "MOE")

```

```{r}
Z_92 = qnorm((1+0.92)/2)
E_92 = Z_92*sqrt((P_Yes*P_No)/len)
CIUP_92 = P_Yes + E_92
CILOW_92 = P_Yes - E_92
CIMID_92 = E_92
CIWidth_92 = 2*E_92
intercepts_92 = data.frame("92%",round(CIUP_92,3),round(CILOW_92,3),round(CIWidth_92,3),round(E_92,3))
colnames(intercepts_92) <- c("percentage", "CLUPPER", "CILOWER", "CIWIDTH" , "MOE")


```

```{r}
Z_94 = qnorm((1+0.94)/2)
E_94 = Z_94*sqrt((P_Yes*P_No)/len)
CIUP_94 = P_Yes + E_94
CILOW_94 = P_Yes - E_94
CIMID_94 = E_94
CIWidth_94 = 2*E_94
intercepts_94 = data.frame("94%",round(CIUP_94,3),round(CILOW_94,3),round(CIWidth_94,3),round(E_94,3))
colnames(intercepts_94) <- c("percentage", "CLUPPER", "CILOWER", "CIWIDTH" , "MOE")
Final_df = rbind(Final_df,intercepts_90)
Final_df = rbind(Final_df,intercepts_92)
Final_df = rbind(Final_df,intercepts_94)
Final_Table = (Final_df)

```

![](D:\Users\Admin\Desktop\\final table.PNG)

<b><br> Observation 4 </b><br>
1.The change in the margin of error with the change in confidence interval percent is also seen in the discrete data collection.
2.The 94 percent confidence interval has the largest margin of error of 0.066.
3.The population parameter would have a margin of error of 5.7 percent when estimated at a 90% confidence interval.
4.The population parameter would have a margin of error of 6.1 percent when estimated at a 92% confidence interval.


```{r}
P1 = c(Pet_Yes,Pet_No)
pie(P1,labels = c(paste(round((P_Yes*100),1),"%"),paste(round((P_No*100),1),"%")),main = "Percentage of people having pets",col = rainbow(length(P1)))
legend("topright", c("Yes","No"), fill = rainbow(length(P1)),cex = 0.6)


```
<b><br>Pie chart</b><br>
According to the pie chart, the population is divided into two nearly equal sections, with 52.9 percent of the population preferring to have pets at home and the other preferring not to.



<b><br>Conclusion:</b><br>
The difference between two different statistical tests, namely the z-test and the t-test, was demonstrated in the initial task. The t-test is also known as a one-variable hypothesis test based on the t-statistic, in which the average is calculated and the population variance, or standard deviation, is estimated from the sample. The Z-test, on the other hand, is a univariate test that uses a conventional normal distribution. The computations for Confidence Intervals for a population proportion were implemented in the next task. Because the data had categorical values, this method was used. The Z-test was utilized for this task because there were more than 30 observations.
We were able to use this assignment to build several types of hypothesis testing and determine the Margin of Errors for various datasets.


<b><br>Bibliography</b><br>
1.Novisurvey posted by Elizabeth in category: survey software articles on 5/23/2018.Retrieved on 22nd November  https://novisurvey.net/blog/four-reasons-to-conduct-a-salary-survey-for-your-company--.aspx

2.Confidence Interval Retrived on 22ndNovember https://en.wikipedia.org/wiki/Confidence_interval

3.Statistics Simplified Statology published on May 5 2021 by Zach Retrieved on 22nd November https://www.statology.org/confidence-interval-real-life-example/

4.T-Interval (t statistics) Published by Solomon Xie on January 12,2019. Retrieved on 22nd November https://medium.com/statistical-guess/t-interval-t-statistics-f45590e1367d 

<b><br>Appendix</b><br>
R Markdown file is attached with the report by the name Project2_Vaidehi_Patole.Rmd
